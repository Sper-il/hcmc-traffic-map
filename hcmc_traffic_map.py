import streamlit as st
import osmnx as ox
import folium
from streamlit_folium import st_folium
import pandas as pd
import warnings
import pickle
import os
import hashlib
import json
from datetime import datetime, timedelta
import numpy as np
import math
import gzip
import zlib
from concurrent.futures import ThreadPoolExecutor, as_completed
from functools import lru_cache

# ·∫®n c·∫£nh b√°o
warnings.filterwarnings('ignore')

# C·∫•u h√¨nh trang web (title, layout)
st.set_page_config(
    page_title="B·∫£n ƒê·ªì Giao Th√¥ng TP.HCM",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ·∫®n c√°c ph·∫ßn t·ª≠ m·∫∑c ƒë·ªãnh c·ªßa Streamlit (Menu, Footer)
hide_streamlit_style = """
<style>
#MainMenu {visibility: hidden;}
footer {visibility: hidden;}
header {visibility: hidden;}
</style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

# C·∫•u h√¨nh OSMnx
ox.settings.timeout = 1000  # TƒÉng th·ªùi gian ch·ªù cho c√°c khu v·ª±c l·ªõn
ox.settings.use_cache = True
ox.settings.log_console = False

# T·∫°o th∆∞ m·ª•c cache n·∫øu ch∆∞a t·ªìn t·∫°i
CACHE_DIR = "map_cache"
MAP_CACHE_DIR = os.path.join(CACHE_DIR, "folium_maps")
os.makedirs(CACHE_DIR, exist_ok=True)
os.makedirs(MAP_CACHE_DIR, exist_ok=True)

# Danh s√°ch g·ª£i √Ω s·∫µn
DISTRICTS = {
    "Qu·∫≠n 1": "District 1, Ho Chi Minh City, Vietnam",
    "Qu·∫≠n 3": "District 3, Ho Chi Minh City, Vietnam",
    "Qu·∫≠n 4": "District 4, Ho Chi Minh City, Vietnam",
    "Qu·∫≠n 5": "District 5, Ho Chi Minh City, Vietnam",
    "Qu·∫≠n 6": "District 6, Ho Chi Minh City, Vietnam",
    "Qu·∫≠n 7": "District 7, Ho Chi Minh City, Vietnam",
    "Qu·∫≠n 8": "District 8, Ho Chi Minh City, Vietnam",
    "Qu·∫≠n 10": "District 10, Ho Chi Minh City, Vietnam",
    "Qu·∫≠n 11": "District 11, Ho Chi Minh City, Vietnam",
    "Qu·∫≠n 12": "District 12, Ho Chi Minh City, Vietnam",
    "Qu·∫≠n B√¨nh Th·∫°nh": "Binh Thanh District, Ho Chi Minh City, Vietnam",
    "Qu·∫≠n G√≤ V·∫•p": "Go Vap District, Ho Chi Minh City, Vietnam",
    "Qu·∫≠n Ph√∫ Nhu·∫≠n": "Phu Nhuan District, Ho Chi Minh City, Vietnam",
    "Qu·∫≠n T√¢n B√¨nh": "Tan Binh District, Ho Chi Minh City, Vietnam",
    "Qu·∫≠n T√¢n Ph√∫": "Tan Phu District, Ho Chi Minh City, Vietnam",
    "Qu·∫≠n B√¨nh T√¢n": "Binh Tan District, Ho Chi Minh City, Vietnam",
    "TP. Th·ªß ƒê·ª©c": "Thu Duc City, Ho Chi Minh City, Vietnam",
    "Huy·ªán B√¨nh Ch√°nh": "Binh Chanh District, Ho Chi Minh City, Vietnam",
    "Huy·ªán C·ªß Chi": "Cu Chi District, Ho Chi Minh City, Vietnam",
    "Huy·ªán Nh√† B√®": "Nha Be District, Ho Chi Minh City, Vietnam",
    "Huy·ªán H√≥c M√¥n": "Hoc Mon District, Ho Chi Minh City, Vietnam",
    "Huy·ªán C·∫ßn Gi·ªù": "Can Gio District, Ho Chi Minh City, Vietnam",
    "To√†n Th√†nh Ph·ªë (R·∫•t Ch·∫≠m üê¢)": "Ho Chi Minh City, Vietnam"
}

# Bi·∫øn to√†n c·ª•c ƒë·ªÉ cache trong b·ªô nh·ªõ (tr√°nh ƒë·ªçc file nhi·ªÅu l·∫ßn)
_MEMORY_CACHE = {}
_FOLIUM_MAP_CACHE = {}  # Cache cho b·∫£n ƒë·ªì Folium
_PICKLE_PROTOCOL = pickle.HIGHEST_PROTOCOL  # S·ª≠ d·ª•ng protocol cao nh·∫•t cho t·ªëc ƒë·ªô t·ªët nh·∫•t

# H·∫±ng s·ªë cho t√≠nh to√°n nhanh
_EARTH_RADIUS = 6371000  # B√°n k√≠nh Tr√°i ƒê·∫•t (m√©t)
_DEG_TO_RAD = math.pi / 180.0  # Chuy·ªÉn ƒë·ªïi ƒë·ªô sang radian


@lru_cache(maxsize=1000)
def haversine_distance(lat1, lon1, lat2, lon2):
    """
    T√≠nh kho·∫£ng c√°ch Haversine v·ªõi caching ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô
    S·ª≠ d·ª•ng lru_cache ƒë·ªÉ tr√°nh t√≠nh to√°n l·∫°i c√°c c·∫∑p t·ªça ƒë·ªô gi·ªëng nhau
    """
    # Chuy·ªÉn ƒë·ªïi ƒë·ªô sang radian
    lat1_rad = lat1 * _DEG_TO_RAD
    lon1_rad = lon1 * _DEG_TO_RAD
    lat2_rad = lat2 * _DEG_TO_RAD
    lon2_rad = lon2 * _DEG_TO_RAD

    # Ch√™nh l·ªách t·ªça ƒë·ªô
    dlat = lat2_rad - lat1_rad
    dlon = lon2_rad - lon1_rad

    # C√¥ng th·ª©c Haversine t·ªëi ∆∞u
    a = math.sin(dlat / 2) ** 2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlon / 2) ** 2
    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))

    return _EARTH_RADIUS * c


def calculate_route_length_fast(coords):
    """
    T√≠nh chi·ªÅu d√†i th·ª±c t·∫ø c·ªßa tuy·∫øn ƒë∆∞·ªùng t·ª´ t·ªça ƒë·ªô (t√≠nh b·∫±ng m√©t)
    Phi√™n b·∫£n t·ªëi ∆∞u h√≥a t·ªëc ƒë·ªô
    """
    if len(coords) < 2:
        return 0.0

    total_distance = 0.0

    # T√≠nh kho·∫£ng c√°ch gi·ªØa c√°c ƒëi·ªÉm li√™n ti·∫øp
    prev_lat, prev_lon = coords[0]
    for i in range(1, len(coords)):
        curr_lat, curr_lon = coords[i]
        total_distance += haversine_distance(prev_lat, prev_lon, curr_lat, curr_lon)
        prev_lat, prev_lon = curr_lat, curr_lon

    return total_distance


def calculate_total_length_parallel(edges, max_workers=4):
    """
    T√≠nh t·ªïng chi·ªÅu d√†i c·ªßa t·∫•t c·∫£ c√°c tuy·∫øn ƒë∆∞·ªùng s·ª≠ d·ª•ng parallel processing
    """
    if len(edges) == 0:
        return 0.0

    # Chuy·ªÉn ƒë·ªïi edges th√†nh danh s√°ch ƒë·ªÉ x·ª≠ l√Ω song song
    edges_list = []
    for idx, row in edges.iterrows():
        if hasattr(row.geometry, 'coords'):
            try:
                coords = [(lat, lon) for lon, lat in row.geometry.coords]
                if len(coords) >= 2:
                    edges_list.append(coords)
            except:
                continue

    if not edges_list:
        return 0.0

    # S·ª≠ d·ª•ng ThreadPoolExecutor ƒë·ªÉ t√≠nh to√°n song song
    total_length_m = 0.0
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # G·ª≠i c√°c task t√≠nh to√°n
        future_to_coords = {executor.submit(calculate_route_length_fast, coords): coords for coords in edges_list}

        # Thu th·∫≠p k·∫øt qu·∫£
        for future in as_completed(future_to_coords):
            try:
                total_length_m += future.result()
            except Exception:
                continue

    return total_length_m / 1000  # Chuy·ªÉn sang km


class CacheManager:
    """Qu·∫£n l√Ω cache cho ·ª©ng d·ª•ng v·ªõi t·ªëi ∆∞u h√≥a t·ªëc ƒë·ªô"""

    @staticmethod
    def get_cache_key(place_name, detailed=False):
        """T·∫°o key cache t·ª´ t√™n ƒë·ªãa ƒëi·ªÉm"""
        cache_string = f"{place_name}_{detailed}"
        return hashlib.md5(cache_string.encode()).hexdigest()

    @staticmethod
    def get_folium_cache_key(place_name, detailed=False, edges_hash=None):
        """T·∫°o key cache cho b·∫£n ƒë·ªì Folium"""
        if edges_hash:
            cache_string = f"folium_{place_name}_{detailed}_{edges_hash}"
        else:
            cache_string = f"folium_{place_name}_{detailed}"
        return hashlib.md5(cache_string.encode()).hexdigest()

    @staticmethod
    def get_cache_info_path():
        """L·∫•y ƒë∆∞·ªùng d·∫´n file th√¥ng tin cache"""
        return os.path.join(CACHE_DIR, "cache_info.json")

    @staticmethod
    def get_cache_file_path(cache_key, compressed=True):
        """L·∫•y ƒë∆∞·ªùng d·∫´n file cache d·ªØ li·ªáu"""
        if compressed:
            return os.path.join(CACHE_DIR, f"{cache_key}.pkl.gz")
        else:
            return os.path.join(CACHE_DIR, f"{cache_key}.pkl")

    @staticmethod
    def get_folium_cache_path(cache_key):
        """L·∫•y ƒë∆∞·ªùng d·∫´n file cache b·∫£n ƒë·ªì Folium"""
        return os.path.join(MAP_CACHE_DIR, f"{cache_key}.html")

    @staticmethod
    def get_metadata_file_path(cache_key):
        """L·∫•y ƒë∆∞·ªùng d·∫´n file metadata"""
        return os.path.join(CACHE_DIR, f"{cache_key}_meta.json")

    @staticmethod
    def load_cache_info():
        """T·∫£i th√¥ng tin cache t·ª´ file"""
        info_path = CacheManager.get_cache_info_path()
        if os.path.exists(info_path):
            try:
                with open(info_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                return {}
        return {}

    @staticmethod
    def save_cache_info(cache_info):
        """L∆∞u th√¥ng tin cache v√†o file"""
        info_path = CacheManager.get_cache_info_path()
        with open(info_path, 'w', encoding='utf-8') as f:
            json.dump(cache_info, f, ensure_ascii=False, indent=2)

    @staticmethod
    def is_cache_valid(cache_key, max_age_days=30):
        """Ki·ªÉm tra cache c√≤n h·ª£p l·ªá kh√¥ng"""
        meta_path = CacheManager.get_metadata_file_path(cache_key)
        if not os.path.exists(meta_path):
            return False

        try:
            with open(meta_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)

            # Ki·ªÉm tra th·ªùi gian t·∫°o
            created_time = datetime.fromisoformat(metadata.get('created_at', '2000-01-01'))
            age = datetime.now() - created_time

            return age.days < max_age_days
        except:
            return False

    @staticmethod
    def is_folium_cache_valid(cache_key, max_age_days=30):
        """Ki·ªÉm tra cache b·∫£n ƒë·ªì Folium c√≤n h·ª£p l·ªá kh√¥ng"""
        cache_path = CacheManager.get_folium_cache_path(cache_key)
        if not os.path.exists(cache_path):
            return False

        try:
            # Ki·ªÉm tra th·ªùi gian s·ª≠a ƒë·ªïi file
            mod_time = datetime.fromtimestamp(os.path.getmtime(cache_path))
            age = datetime.now() - mod_time
            return age.days < max_age_days
        except:
            return False

    @staticmethod
    def update_cache_metadata(cache_key, place_name, edges_count, total_length_km, detailed=False, compressed=True):
        """C·∫≠p nh·∫≠t metadata cho cache"""
        cache_file_path = CacheManager.get_cache_file_path(cache_key, compressed)
        file_size_kb = 0
        if os.path.exists(cache_file_path):
            file_size_kb = os.path.getsize(cache_file_path) / 1024

        metadata = {
            'place_name': place_name,
            'detailed': detailed,
            'edges_count': edges_count,
            'total_length_km': total_length_km,
            'created_at': datetime.now().isoformat(),
            'size_kb': file_size_kb,
            'compressed': compressed
        }

        meta_path = CacheManager.get_metadata_file_path(cache_key)
        with open(meta_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)

        # C·∫≠p nh·∫≠t cache info
        cache_info = CacheManager.load_cache_info()
        cache_info[cache_key] = {
            'name': place_name,
            'detailed': detailed,
            'count': edges_count,
            'total_length_km': total_length_km,
            'created': metadata['created_at'],
            'size_kb': metadata['size_kb'],
            'compressed': compressed
        }
        CacheManager.save_cache_info(cache_info)

    @staticmethod
    def save_cache_data(cache_key, edges, compressed=True):
        """L∆∞u d·ªØ li·ªáu cache v·ªõi t·ªëi ∆∞u h√≥a"""
        cache_file_path = CacheManager.get_cache_file_path(cache_key, compressed)

        try:
            if compressed:
                # S·ª≠ d·ª•ng gzip ƒë·ªÉ n√©n d·ªØ li·ªáu
                with gzip.open(cache_file_path, 'wb') as f:
                    pickle.dump(edges, f, protocol=_PICKLE_PROTOCOL)
            else:
                # L∆∞u kh√¥ng n√©n
                with open(cache_file_path, 'wb') as f:
                    pickle.dump(edges, f, protocol=_PICKLE_PROTOCOL)

            return True
        except Exception as e:
            st.warning(f"‚ö†Ô∏è L·ªói khi l∆∞u cache: {e}")
            return False

    @staticmethod
    def load_cache_data(cache_key, compressed=True):
        """T·∫£i d·ªØ li·ªáu cache v·ªõi t·ªëi ∆∞u h√≥a"""
        cache_file_path = CacheManager.get_cache_file_path(cache_key, compressed)

        if not os.path.exists(cache_file_path):
            return None

        try:
            if compressed:
                with gzip.open(cache_file_path, 'rb') as f:
                    return pickle.load(f)
            else:
                with open(cache_file_path, 'rb') as f:
                    return pickle.load(f)
        except Exception as e:
            st.warning(f"‚ö†Ô∏è L·ªói khi ƒë·ªçc cache: {e}")
            return None

    @staticmethod
    def save_folium_map(cache_key, folium_map):
        """L∆∞u b·∫£n ƒë·ªì Folium d∆∞·ªõi d·∫°ng HTML"""
        try:
            cache_path = CacheManager.get_folium_cache_path(cache_key)
            folium_map.save(cache_path)

            # L∆∞u metadata nh·ªè
            meta_path = os.path.join(MAP_CACHE_DIR, f"{cache_key}_meta.json")
            metadata = {
                'created_at': datetime.now().isoformat(),
                'size_kb': os.path.getsize(cache_path) / 1024
            }
            with open(meta_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)

            return True
        except Exception as e:
            st.warning(f"‚ö†Ô∏è L·ªói khi l∆∞u b·∫£n ƒë·ªì: {e}")
            return False

    @staticmethod
    def load_folium_map(cache_key):
        """T·∫£i b·∫£n ƒë·ªì Folium t·ª´ cache HTML"""
        try:
            cache_path = CacheManager.get_folium_cache_path(cache_key)

            if not os.path.exists(cache_path):
                return None

            # ƒê·ªçc n·ªôi dung HTML
            with open(cache_path, 'r', encoding='utf-8') as f:
                html_content = f.read()

            return html_content
        except Exception as e:
            st.warning(f"‚ö†Ô∏è L·ªói khi ƒë·ªçc b·∫£n ƒë·ªì: {e}")
            return None

    @staticmethod
    def get_edges_hash(edges):
        """T·∫°o hash cho edges ƒë·ªÉ x√°c ƒë·ªãnh xem b·∫£n ƒë·ªì c√≥ c·∫ßn v·∫Ω l·∫°i kh√¥ng"""
        if edges is None or edges.empty:
            return "empty"

        # T·∫°o hash t·ª´ c√°c thu·ªôc t√≠nh c∆° b·∫£n c·ªßa edges
        hash_data = {
            'shape': edges.shape,
            'total_length': edges.attrs.get('total_length_km', 0) if hasattr(edges, 'attrs') else 0,
            'columns': list(edges.columns) if hasattr(edges, 'columns') else [],
            'count': len(edges)
        }

        return hashlib.md5(json.dumps(hash_data, sort_keys=True).encode()).hexdigest()


def get_graph_data(place_name, detailed=False):
    """L·∫•y d·ªØ li·ªáu ƒë·ªì th·ªã t·ª´ cache ho·∫∑c OSM - Phi√™n b·∫£n t·ªëi ∆∞u h√≥a"""

    cache_key = CacheManager.get_cache_key(place_name, detailed)
    compressed = True  # S·ª≠ d·ª•ng n√©n m·∫∑c ƒë·ªãnh

    # 1. Ki·ªÉm tra cache trong b·ªô nh·ªõ
    if cache_key in _MEMORY_CACHE:
        edges, metadata = _MEMORY_CACHE[cache_key]
        st.info(f"‚ö° ƒêang t·∫£i t·ª´ b·ªô nh·ªõ: {metadata['edges_count']} tuy·∫øn ƒë∆∞·ªùng")
        return edges

    # 2. Ki·ªÉm tra cache tr√™n ƒëƒ©a
    if CacheManager.is_cache_valid(cache_key):
        try:
            with st.spinner("üöÄ ƒêang ƒë·ªçc d·ªØ li·ªáu t·ª´ cache (nhanh)..."):
                # ƒê·ªçc d·ªØ li·ªáu t·ª´ file cache
                edges = CacheManager.load_cache_data(cache_key, compressed)

                if edges is not None:
                    # ƒê·ªçc metadata
                    meta_path = CacheManager.get_metadata_file_path(cache_key)
                    if os.path.exists(meta_path):
                        with open(meta_path, 'r', encoding='utf-8') as f:
                            metadata = json.load(f)
                    else:
                        # T√≠nh to√°n l·∫°i t·ªïng chi·ªÅu d√†i n·∫øu metadata kh√¥ng c√≥
                        total_length_km = calculate_total_length_parallel(edges)
                        metadata = {
                            'edges_count': len(edges),
                            'total_length_km': total_length_km
                        }

                    # L∆∞u v√†o cache b·ªô nh·ªõ
                    _MEMORY_CACHE[cache_key] = (edges, metadata)

                    st.success(
                        f"‚úÖ ƒê√£ t·∫£i t·ª´ cache: {len(edges)} tuy·∫øn ƒë∆∞·ªùng (k√≠ch th∆∞·ªõc: {metadata.get('size_kb', 0):.1f} KB)")
                    return edges
        except Exception as e:
            st.warning(f"‚ö†Ô∏è L·ªói khi ƒë·ªçc cache: {e}. ƒêang t·∫£i m·ªõi t·ª´ internet...")

    # 3. N·∫øu kh√¥ng c√≥ cache h·ª£p l·ªá, t·∫£i t·ª´ OSM
    return download_and_cache_data(place_name, detailed, cache_key, compressed)


def download_and_cache_data(place_name, detailed, cache_key, compressed=True):
    """T·∫£i d·ªØ li·ªáu t·ª´ OSM v√† l∆∞u v√†o cache v·ªõi t·ªëi ∆∞u h√≥a"""

    # X√°c ƒë·ªãnh custom_filter d·ª±a tr√™n lo·∫°i khu v·ª±c v√† ch·∫ø ƒë·ªô chi ti·∫øt
    custom_filter = None

    # N·∫øu l√† ch·∫ø ƒë·ªô chi ti·∫øt (ƒë·∫∑c bi·ªát cho Qu·∫≠n 1)
    if detailed:
        # L·∫•y t·∫•t c·∫£ c√°c lo·∫°i ƒë∆∞·ªùng, bao g·ªìm c·∫£ ƒë∆∞·ªùng nh·ªè
        custom_filter = '["highway"~"motorway|trunk|primary|secondary|tertiary|residential|service|living_street|unclassified"]'
        st.info("üîç ƒêang t·∫£i chi ti·∫øt: L·∫•y c·∫£ ƒë∆∞·ªùng nh·ªè (h·∫ªm, ng√µ)...")
    elif "Ho Chi Minh City" in place_name and "District" not in place_name and "Qu·∫≠n" not in place_name:
        # To√†n th√†nh ph·ªë - ch·ªâ l·∫•y ƒë∆∞·ªùng ch√≠nh
        custom_filter = '["highway"~"motorway|trunk|primary|secondary"]'
    else:
        # C√°c qu·∫≠n kh√°c - l·∫•y ƒë∆∞·ªùng ch√≠nh v√† ƒë∆∞·ªùng ph·ª•
        custom_filter = '["highway"~"motorway|trunk|primary|secondary|tertiary"]'

    try:
        with st.spinner(f"üåê ƒêang t·∫£i d·ªØ li·ªáu t·ª´ OpenStreetMap..."):
            if custom_filter:
                G = ox.graph_from_place(
                    place_name,
                    network_type='drive',
                    simplify=True,
                    custom_filter=custom_filter
                )
            else:
                G = ox.graph_from_place(
                    place_name,
                    network_type='drive',
                    simplify=True
                )

        nodes, edges = ox.graph_to_gdfs(G)

        # T√≠nh t·ªïng chi·ªÅu d√†i c√°c tuy·∫øn ƒë∆∞·ªùng v·ªõi parallel processing
        with st.spinner("üìè ƒêang t√≠nh to√°n chi·ªÅu d√†i ƒë∆∞·ªùng..."):
            total_length_km = calculate_total_length_parallel(edges)

        # L∆∞u v√†o cache
        if CacheManager.save_cache_data(cache_key, edges, compressed):
            # C·∫≠p nh·∫≠t metadata
            CacheManager.update_cache_metadata(cache_key, place_name, len(edges), total_length_km, detailed, compressed)

            # L∆∞u v√†o cache b·ªô nh·ªõ
            metadata = {
                'place_name': place_name,
                'detailed': detailed,
                'edges_count': len(edges),
                'total_length_km': total_length_km,
                'created_at': datetime.now().isoformat(),
                'size_kb': os.path.getsize(CacheManager.get_cache_file_path(cache_key, compressed)) / 1024,
                'compressed': compressed
            }
            _MEMORY_CACHE[cache_key] = (edges, metadata)

            st.success(
                f"üíæ ƒê√£ l∆∞u cache: {len(edges)} tuy·∫øn ƒë∆∞·ªùng, {total_length_km:.1f} km (k√≠ch th∆∞·ªõc: {metadata['size_kb']:.1f} KB)")

        return edges

    except Exception as e:
        st.error(f"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {e}")
        return None


class HCMTrafficMap:
    def __init__(self):
        self.cache_info = CacheManager.load_cache_info()
        self.current_edges_hash = None

    def create_sidebar(self):
        st.sidebar.title("‚öôÔ∏è T√πy Ch·ªçn")

        # Hi·ªÉn th·ªã th√¥ng tin cache
        self.display_cache_info()

        # Th√™m n√∫t x√≥a cache
        st.sidebar.markdown("---")
        col1, col2, col3 = st.sidebar.columns(3)

        with col1:
            if st.button("üóëÔ∏è X√≥a cache", help="X√≥a t·∫•t c·∫£ d·ªØ li·ªáu ƒë√£ l∆∞u ƒë·ªÉ t·∫£i l·∫°i t·ª´ ƒë·∫ßu"):
                self.clear_all_cache()

        with col2:
            if st.button("üóëÔ∏è Cache Q1", help="Ch·ªâ x√≥a cache c·ªßa Qu·∫≠n 1"):
                self.clear_district1_cache()

        with col3:
            if st.button("üóëÔ∏è B·∫£n ƒë·ªì", help="X√≥a cache b·∫£n ƒë·ªì Folium"):
                self.clear_folium_cache()

        # Th√™m t√πy ch·ªçn chi ti·∫øt cho Qu·∫≠n 1
        st.sidebar.markdown("---")
        self.detailed_mode = False

        # T·∫°o danh s√°ch l·ª±a ch·ªçn + M·ª•c t√πy ch·ªânh
        options = list(DISTRICTS.keys()) + ["üîç Nh·∫≠p ƒë·ªãa ƒëi·ªÉm t√πy ch·ªânh..."]

        selection = st.sidebar.selectbox(
            "Ch·ªçn khu v·ª±c:",
            options,
            index=0
        )

        # Ki·ªÉm tra n·∫øu ch·ªçn Qu·∫≠n 1 th√¨ hi·ªÉn th·ªã t√πy ch·ªçn chi ti·∫øt
        if selection == "Qu·∫≠n 1":
            self.detailed_mode = st.sidebar.checkbox(
                "üîé Ch·∫ø ƒë·ªô chi ti·∫øt (hi·ªÉn th·ªã c·∫£ h·∫ªm, ng√µ)",
                value=True,
                help="B·∫≠t ƒë·ªÉ hi·ªÉn th·ªã t·∫•t c·∫£ c√°c tuy·∫øn ƒë∆∞·ªùng, bao g·ªìm c·∫£ ƒë∆∞·ªùng nh·ªè trong Qu·∫≠n 1"
            )
            if self.detailed_mode:
                st.sidebar.caption("‚ö†Ô∏è Ch·∫ø ƒë·ªô chi ti·∫øt c√≥ th·ªÉ t·∫£i ch·∫≠m h∆°n do c√≥ nhi·ªÅu ƒë∆∞·ªùng")

        # T√πy ch·ªçn t·∫£i l·∫°i b·∫£n ƒë·ªì
        st.sidebar.markdown("---")
        self.force_reload = st.sidebar.checkbox(
            "üîÑ T·∫£i l·∫°i b·∫£n ƒë·ªì",
            value=False,
            help="Bu·ªôc t·∫£i l·∫°i b·∫£n ƒë·ªì t·ª´ ƒë·∫ßu (b·ªè qua cache b·∫£n ƒë·ªì)"
        )

        # X·ª≠ l√Ω logic ch·ªçn
        if selection == "üîç Nh·∫≠p ƒë·ªãa ƒëi·ªÉm t√πy ch·ªânh...":
            st.sidebar.markdown("---")
            custom_input = st.sidebar.text_input(
                "G√µ t√™n ƒë·ªãa ƒëi·ªÉm (VD: Thu Duc City, S√¢n bay T√¢n S∆°n Nh·∫•t):",
                "Ben Thanh Market"
            )

            display_name = custom_input

            # T·ª± ƒë·ªông th√™m context ƒë·ªÉ t√¨m ki·∫øm ch√≠nh x√°c h∆°n
            place_query = custom_input

            input_lower = custom_input.lower()
            if "vietnam" not in input_lower and "hcmc" not in input_lower and "h·ªì ch√≠ minh" not in input_lower:
                place_query = custom_input + ", Ho Chi Minh City, Vietnam"
                st.sidebar.caption("ƒê√£ t·ª± ƒë·ªông th√™m `, Ho Chi Minh City, Vietnam` v√†o t√¨m ki·∫øm.")

            return place_query, display_name, self.detailed_mode

        else:
            # Ch·ªçn t·ª´ menu c·ªë ƒë·ªãnh
            return DISTRICTS[selection], selection, self.detailed_mode

    def display_cache_info(self):
        """Hi·ªÉn th·ªã th√¥ng tin cache trong sidebar"""
        total_size = sum(info.get('size_kb', 0) for info in self.cache_info.values())
        total_length = sum(info.get('total_length_km', 0) for info in self.cache_info.values())
        compressed_count = sum(1 for info in self.cache_info.values() if info.get('compressed', False))

        # ƒê·∫øm file cache b·∫£n ƒë·ªì
        folium_cache_count = 0
        folium_cache_size = 0
        if os.path.exists(MAP_CACHE_DIR):
            folium_files = [f for f in os.listdir(MAP_CACHE_DIR) if f.endswith('.html')]
            folium_cache_count = len(folium_files)
            for file in folium_files:
                folium_cache_size += os.path.getsize(os.path.join(MAP_CACHE_DIR, file)) / 1024

        st.sidebar.markdown(f"### üìä Th√¥ng tin Cache")
        st.sidebar.markdown(f"**S·ªë khu v·ª±c:** {len(self.cache_info)}")
        st.sidebar.markdown(f"**S·ªë b·∫£n ƒë·ªì:** {folium_cache_count}")
        st.sidebar.markdown(f"**ƒê√£ n√©n:** {compressed_count}/{len(self.cache_info)}")
        st.sidebar.markdown(f"**Dung l∆∞·ª£ng d·ªØ li·ªáu:** {total_size:.1f} KB")
        st.sidebar.markdown(f"**Dung l∆∞·ª£ng b·∫£n ƒë·ªì:** {folium_cache_size:.1f} KB")
        st.sidebar.markdown(f"**T·ªïng chi·ªÅu d√†i:** {total_length:.1f} km")

        # Hi·ªÉn th·ªã danh s√°ch cache
        if self.cache_info:
            st.sidebar.markdown("**Top 5 cache l·ªõn nh·∫•t:**")
            # S·∫Øp x·∫øp theo k√≠ch th∆∞·ªõc
            sorted_cache = sorted(self.cache_info.items(),
                                  key=lambda x: x[1].get('size_kb', 0),
                                  reverse=True)[:5]

            for cache_key, info in sorted_cache:
                name = info.get('name', 'Unknown')[:20] + "..." if len(info.get('name', '')) > 20 else info.get('name',
                                                                                                                'Unknown')
                count = info.get('count', 0)
                length = info.get('total_length_km', 0)
                size = info.get('size_kb', 0)
                compressed = "‚úì" if info.get('compressed', False) else "‚úó"
                st.sidebar.caption(f"‚Ä¢ {name}: {count} ƒë∆∞·ªùng, {length:.1f} km, {size:.1f} KB [{compressed}]")

            if len(self.cache_info) > 5:
                st.sidebar.caption(f"... v√† {len(self.cache_info) - 5} khu v·ª±c kh√°c")

    def clear_all_cache(self):
        """X√≥a t·∫•t c·∫£ file cache trong th∆∞ m·ª•c cache"""
        try:
            # X√≥a cache trong b·ªô nh·ªõ
            global _MEMORY_CACHE, _FOLIUM_MAP_CACHE
            _MEMORY_CACHE.clear()
            _FOLIUM_MAP_CACHE.clear()

            # X√≥a file cache
            cache_files = [f for f in os.listdir(CACHE_DIR) if f.endswith(('.pkl', '.json', '.gz'))]
            deleted_count = 0

            for file in cache_files:
                try:
                    os.remove(os.path.join(CACHE_DIR, file))
                    deleted_count += 1
                except:
                    pass

            # X√≥a cache b·∫£n ƒë·ªì
            if os.path.exists(MAP_CACHE_DIR):
                map_files = [f for f in os.listdir(MAP_CACHE_DIR) if f.endswith(('.html', '.json'))]
                for file in map_files:
                    try:
                        os.remove(os.path.join(MAP_CACHE_DIR, file))
                        deleted_count += 1
                    except:
                        pass

            # X√≥a cache info
            CacheManager.save_cache_info({})

            st.sidebar.success(f"‚úÖ ƒê√£ x√≥a {deleted_count} file cache")
            st.rerun()

        except Exception as e:
            st.sidebar.error(f"‚ùå L·ªói khi x√≥a cache: {e}")

    def clear_district1_cache(self):
        """X√≥a cache c·ªßa Qu·∫≠n 1 (c·∫£ ch·∫ø ƒë·ªô th∆∞·ªùng v√† chi ti·∫øt)"""
        try:
            # X√°c ƒë·ªãnh c√°c key cache c·ªßa Qu·∫≠n 1
            district1_normal = CacheManager.get_cache_key("District 1, Ho Chi Minh City, Vietnam", detailed=False)
            district1_detailed = CacheManager.get_cache_key("District 1, Ho Chi Minh City, Vietnam", detailed=True)

            # X√≥a t·ª´ cache b·ªô nh·ªõ
            global _MEMORY_CACHE, _FOLIUM_MAP_CACHE
            for key in [district1_normal, district1_detailed]:
                if key in _MEMORY_CACHE:
                    del _MEMORY_CACHE[key]
                # X√≥a cache b·∫£n ƒë·ªì li√™n quan
                folium_keys = [k for k in _FOLIUM_MAP_CACHE.keys() if key in k]
                for f_key in folium_keys:
                    del _FOLIUM_MAP_CACHE[f_key]

            # X√≥a file cache
            cache_files = os.listdir(CACHE_DIR)
            deleted_count = 0

            for file in cache_files:
                file_path = os.path.join(CACHE_DIR, file)
                if file.endswith(('.pkl', '.json', '.gz')):
                    # Ki·ªÉm tra n·∫øu file thu·ªôc cache Qu·∫≠n 1
                    if district1_normal in file or district1_detailed in file:
                        try:
                            os.remove(file_path)
                            deleted_count += 1
                        except:
                            pass

            # X√≥a cache b·∫£n ƒë·ªì
            if os.path.exists(MAP_CACHE_DIR):
                map_files = os.listdir(MAP_CACHE_DIR)
                for file in map_files:
                    file_path = os.path.join(MAP_CACHE_DIR, file)
                    if district1_normal in file or district1_detailed in file:
                        try:
                            os.remove(file_path)
                            deleted_count += 1
                        except:
                            pass

            # C·∫≠p nh·∫≠t cache info
            cache_info = CacheManager.load_cache_info()
            for key in [district1_normal, district1_detailed]:
                if key in cache_info:
                    del cache_info[key]
            CacheManager.save_cache_info(cache_info)

            st.sidebar.success(f"‚úÖ ƒê√£ x√≥a {deleted_count} file cache Qu·∫≠n 1")
            st.rerun()

        except Exception as e:
            st.sidebar.error(f"‚ùå L·ªói khi x√≥a cache Qu·∫≠n 1: {e}")

    def clear_folium_cache(self):
        """X√≥a cache b·∫£n ƒë·ªì Folium"""
        try:
            global _FOLIUM_MAP_CACHE
            _FOLIUM_MAP_CACHE.clear()

            if os.path.exists(MAP_CACHE_DIR):
                map_files = [f for f in os.listdir(MAP_CACHE_DIR) if f.endswith(('.html', '.json'))]
                deleted_count = 0

                for file in map_files:
                    try:
                        os.remove(os.path.join(MAP_CACHE_DIR, file))
                        deleted_count += 1
                    except:
                        pass

                st.sidebar.success(f"‚úÖ ƒê√£ x√≥a {deleted_count} file cache b·∫£n ƒë·ªì")
                st.rerun()
            else:
                st.sidebar.info("‚ÑπÔ∏è Kh√¥ng c√≥ cache b·∫£n ƒë·ªì ƒë·ªÉ x√≥a")

        except Exception as e:
            st.sidebar.error(f"‚ùå L·ªói khi x√≥a cache b·∫£n ƒë·ªì: {e}")

    def load_data(self, place_query, display_name, detailed=False):
        try:
            with st.spinner(f"üöÄ ƒêang t·∫£i d·ªØ li·ªáu: {display_name}..."):
                edges = get_graph_data(place_query, detailed)

            if edges is not None:
                # L·∫•y metadata t·ª´ cache b·ªô nh·ªõ
                cache_key = CacheManager.get_cache_key(place_query, detailed)
                if cache_key in _MEMORY_CACHE:
                    edges_data, metadata = _MEMORY_CACHE[cache_key]
                    total_length_km = metadata.get('total_length_km', 0)
                else:
                    # T√≠nh t·ªïng chi·ªÅu d√†i n·∫øu kh√¥ng c√≥ trong cache
                    with st.spinner("üìè ƒêang t√≠nh to√°n chi·ªÅu d√†i..."):
                        total_length_km = calculate_total_length_parallel(edges)

                # Th·ªëng k√™ s·ªë l∆∞·ª£ng ƒë∆∞·ªùng theo lo·∫°i
                if not edges.empty and 'highway' in edges.columns:
                    highway_counts = edges['highway'].value_counts()

                    # Hi·ªÉn th·ªã th·ªëng k√™ trong sidebar
                    st.sidebar.markdown("---")
                    st.sidebar.markdown("### üìà Th·ªëng k√™ ƒë∆∞·ªùng")

                    # L·∫•y top 10 lo·∫°i ƒë∆∞·ªùng ph·ªï bi·∫øn nh·∫•t
                    top_highways = highway_counts.head(10)
                    for hw_type, count in top_highways.items():
                        # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p highway l√† list
                        if isinstance(hw_type, list):
                            hw_type = ', '.join(hw_type)
                        st.sidebar.caption(f"‚Ä¢ {hw_type}: {count} ƒë∆∞·ªùng")

                    st.sidebar.caption(f"**T·ªïng:** {len(edges)} tuy·∫øn ƒë∆∞·ªùng, {total_length_km:.1f} km")

                st.success(f"‚úÖ ƒê√£ t·∫£i: {display_name} ({len(edges)} tuy·∫øn ƒë∆∞·ªùng, {total_length_km:.1f} km)")
                if detailed:
                    st.info(f"üîç ƒêang ·ªü ch·∫ø ƒë·ªô chi ti·∫øt")

                # L∆∞u t·ªïng chi·ªÅu d√†i ƒë·ªÉ s·ª≠ d·ª•ng sau
                edges.attrs['total_length_km'] = total_length_km

                # L∆∞u hash c·ªßa edges
                self.current_edges_hash = CacheManager.get_edges_hash(edges)

            return edges

        except Exception as e:
            st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y ƒë·ªãa ƒëi·ªÉm '{display_name}'!")
            st.info(f"üí° L·ªói chi ti·∫øt: {e}")
            st.info("üí° L·ªói n√†y x·∫£y ra khi OpenStreetMap kh√¥ng nh·∫≠n ra t√™n b·∫°n g√µ. H√£y th·ª≠ g√µ ti·∫øng Anh kh√¥ng d·∫•u nh√©!")
            return None

    def create_map(self, edges, place_query, display_name, detailed=False, force_reload=False):
        """T·∫°o b·∫£n ƒë·ªì Folium, s·ª≠ d·ª•ng cache n·∫øu c√≥"""

        # T·∫°o cache key cho b·∫£n ƒë·ªì
        folium_cache_key = CacheManager.get_folium_cache_key(
            place_query,
            detailed,
            self.current_edges_hash
        )

        # Ki·ªÉm tra cache b·∫£n ƒë·ªì trong b·ªô nh·ªõ
        global _FOLIUM_MAP_CACHE
        if not force_reload and folium_cache_key in _FOLIUM_MAP_CACHE:
            st.info(f"‚ö° ƒêang t·∫£i b·∫£n ƒë·ªì t·ª´ b·ªô nh·ªõ...")
            return _FOLIUM_MAP_CACHE[folium_cache_key]

        # Ki·ªÉm tra cache b·∫£n ƒë·ªì tr√™n ƒëƒ©a
        if not force_reload and CacheManager.is_folium_cache_valid(folium_cache_key):
            try:
                with st.spinner("üöÄ ƒêang t·∫£i b·∫£n ƒë·ªì t·ª´ cache (r·∫•t nhanh)..."):
                    html_content = CacheManager.load_folium_map(folium_cache_key)
                    if html_content:
                        # T·∫°o ƒë·ªëi t∆∞·ª£ng folium map t·ª´ HTML
                        m = folium.Map(location=[10.7769, 106.7009], zoom_start=14)
                        # L∆∞u HTML v√†o cache b·ªô nh·ªõ
                        _FOLIUM_MAP_CACHE[folium_cache_key] = m
                        m._html = html_content  # L∆∞u HTML ƒë·ªÉ hi·ªÉn th·ªã sau

                        # L·∫•y th√¥ng tin k√≠ch th∆∞·ªõc t·ª´ metadata
                        meta_path = os.path.join(MAP_CACHE_DIR, f"{folium_cache_key}_meta.json")
                        if os.path.exists(meta_path):
                            with open(meta_path, 'r', encoding='utf-8') as f:
                                metadata = json.load(f)
                                m.cache_size_kb = metadata.get('size_kb', 0)
                        else:
                            m.cache_size_kb = 0

                        st.success(f"‚úÖ ƒê√£ t·∫£i b·∫£n ƒë·ªì t·ª´ cache ({m.cache_size_kb:.1f} KB)")
                        return m
            except Exception as e:
                st.warning(f"‚ö†Ô∏è L·ªói khi ƒë·ªçc cache b·∫£n ƒë·ªì: {e}. ƒêang t·∫°o b·∫£n ƒë·ªì m·ªõi...")

        # N·∫øu kh√¥ng c√≥ cache h·ª£p l·ªá, t·∫°o b·∫£n ƒë·ªì m·ªõi
        return self._create_new_map(edges, place_query, display_name, detailed, folium_cache_key)

    def _create_new_map(self, edges, place_query, display_name, detailed, folium_cache_key):
        """T·∫°o b·∫£n ƒë·ªì m·ªõi v√† l∆∞u v√†o cache"""
        # T√≠nh t√¢m b·∫£n ƒë·ªì
        if not edges.empty:
            bounds = edges.total_bounds
            center_lat = (bounds[1] + bounds[3]) / 2
            center_lon = (bounds[0] + bounds[2]) / 2
        else:
            # T·ªça ƒë·ªô m·∫∑c ƒë·ªãnh: Qu·∫≠n 1
            center_lat, center_lon = 10.7769, 106.7009

        m = folium.Map(
            location=[center_lat, center_lon],
            zoom_start=15 if len(edges) > 1000 else 14,
            tiles='OpenStreetMap',
            prefer_canvas=True
        )

        # M√ÄU DUY NH·∫§T CHO T·∫§T C·∫¢ C√ÅC LO·∫†I ƒê∆Ø·ªúNG
        UNIFIED_COLOR = '#3388ff'  # M√†u xanh d∆∞∆°ng

        count = 0
        max_edges = 50000  # TƒÉng gi·ªõi h·∫°n cho ch·∫ø ƒë·ªô chi ti·∫øt
        total_displayed_length = 0.0

        # S·ª≠ d·ª•ng progress bar ƒë·ªÉ hi·ªÉn th·ªã ti·∫øn tr√¨nh v·∫Ω
        progress_bar = st.progress(0)
        total_edges = min(len(edges), max_edges)

        # V·∫Ω c√°c tuy·∫øn ƒë∆∞·ªùng v·ªõi t·ªëi ∆∞u h√≥a
        for idx, row in edges.iterrows():
            if count >= max_edges:
                break
            try:
                hw = row.get('highway')
                if isinstance(hw, list):
                    hw = hw[0]

                # ƒêi·ªÅu ch·ªânh ƒë·ªô d√†y ƒë∆∞·ªùng d·ª±a tr√™n lo·∫°i ƒë∆∞·ªùng
                if hw in ['motorway', 'trunk', 'primary']:
                    weight = 3.5
                elif hw in ['secondary']:
                    weight = 2.5
                elif hw in ['tertiary']:
                    weight = 2.0
                elif hw in ['residential', 'living_street', 'unclassified']:
                    weight = 1.5
                elif hw in ['service']:
                    weight = 1.0
                else:
                    weight = 1.5

                if hasattr(row.geometry, 'coords'):
                    # T√≠nh chi·ªÅu d√†i th·ª±c t·∫ø c·ªßa tuy·∫øn ƒë∆∞·ªùng
                    coords = [(lat, lon) for lon, lat in row.geometry.coords]
                    route_length_m = calculate_route_length_fast(coords)
                    total_displayed_length += route_length_m

                    # Format chi·ªÅu d√†i hi·ªÉn th·ªã
                    if route_length_m >= 1000:
                        length_display = f"{route_length_m / 1000:.2f} km"
                    else:
                        length_display = f"{route_length_m:.0f} m"

                    # T·∫°o popup v·ªõi th√¥ng tin chi ti·∫øt
                    popup_text = f"""
                    <div style="font-family: Arial; font-size: 12px;">
                        <b>T√™n ƒë∆∞·ªùng:</b> {row.get('name', 'Kh√¥ng c√≥ t√™n')}<br>
                        <b>Lo·∫°i ƒë∆∞·ªùng:</b> {hw}<br>
                        <b>Chi·ªÅu d√†i:</b> {length_display}<br>
                        <b>S·ªë ƒëi·ªÉm:</b> {len(coords)}
                    </div>
                    """

                    folium.PolyLine(
                        locations=coords,
                        color=UNIFIED_COLOR,
                        weight=weight,
                        opacity=0.8,
                        popup=folium.Popup(popup_text, max_width=300),
                        tooltip=f"{row.get('name', 'ƒê∆∞·ªùng kh√¥ng t√™n')} - {length_display}"
                    ).add_to(m)
                    count += 1

                    # C·∫≠p nh·∫≠t progress bar m·ªói 1000 ƒë∆∞·ªùng
                    if count % 1000 == 0 or count == total_edges:
                        progress = count / total_edges
                        progress_bar.progress(progress)

            except Exception:
                continue

        progress_bar.empty()  # ·∫®n progress bar sau khi ho√†n th√†nh

        # Th√™m marker cho trung t√¢m th√†nh ph·ªë n·∫øu l√† Qu·∫≠n 1
        if "District 1" in str(edges.crs) if edges.crs else False:
            # Th√™m c√°c ƒë·ªãa ƒëi·ªÉm n·ªïi ti·∫øng ·ªü Qu·∫≠n 1
            landmarks = [
                ("Ch·ª£ B·∫øn Th√†nh", 10.772, 106.698),
                ("Nh√† h√°t Th√†nh ph·ªë", 10.777, 106.703),
                ("B∆∞u ƒëi·ªán Trung t√¢m", 10.780, 106.699),
                ("Dinh ƒê·ªôc L·∫≠p", 10.777, 106.695),
                ("B·∫øn B·∫°ch ƒê·∫±ng", 10.773, 106.706)
            ]

            for name, lat, lon in landmarks:
                folium.Marker(
                    location=[lat, lon],
                    popup=name,
                    icon=folium.Icon(color='red', icon='info-sign')
                ).add_to(m)

        # L∆∞u th√¥ng tin chi·ªÅu d√†i ƒë√£ hi·ªÉn th·ªã
        m.total_displayed_length_km = total_displayed_length / 1000
        m.total_displayed_edges = count

        # L∆∞u b·∫£n ƒë·ªì v√†o cache
        if CacheManager.save_folium_map(folium_cache_key, m):
            st.info(f"üíæ ƒê√£ l∆∞u b·∫£n ƒë·ªì v√†o cache")
            # L∆∞u v√†o cache b·ªô nh·ªõ
            _FOLIUM_MAP_CACHE[folium_cache_key] = m

        return m


def main():
    st.markdown("<h1 style='text-align: center; color: #1f77b4;'>üó∫Ô∏è B·∫¢N ƒê·ªí GIAO TH√îNG TP.HCM</h1>",
                unsafe_allow_html=True)

    # Th√¥ng tin phi√™n b·∫£n t·ªëi ∆∞u
    st.sidebar.markdown("---")
    st.sidebar.markdown("**üöÄ Phi√™n b·∫£n t·ªëi ∆∞u h√≥a**")
    st.sidebar.caption("‚Ä¢ Cache n√©n GZIP")
    st.sidebar.caption("‚Ä¢ Parallel processing")
    st.sidebar.caption("‚Ä¢ Memory caching")
    st.sidebar.caption("‚Ä¢ Cache b·∫£n ƒë·ªì Folium")

    app = HCMTrafficMap()

    # 1. Menu ch·ªçn
    place_query, display_name, detailed_mode = app.create_sidebar()

    # 2. T·∫£i & V·∫Ω
    if place_query:
        edges = app.load_data(place_query, display_name, detailed_mode)
        if edges is not None:
            traffic_map = app.create_map(edges, place_query, display_name, detailed_mode, app.force_reload)

            # Ki·ªÉm tra n·∫øu b·∫£n ƒë·ªì c√≥ HTML cache
            if hasattr(traffic_map, '_html'):
                # Hi·ªÉn th·ªã HTML cache
                st.components.v1.html(traffic_map._html, width=1400, height=700)
            else:
                # Hi·ªÉn th·ªã b·∫£n ƒë·ªì th√¥ng th∆∞·ªùng
                st_folium(traffic_map, width=1400, height=700, returned_objects=[])

            # L·∫•y th√¥ng tin t·ªïng chi·ªÅu d√†i t·ª´ edges
            total_length_km = edges.attrs.get('total_length_km', 0)
            displayed_length_km = getattr(traffic_map, 'total_displayed_length_km', 0)
            displayed_edges = getattr(traffic_map, 'total_displayed_edges', 0)

            # Th√¥ng tin cache b·∫£n ƒë·ªì
            if hasattr(traffic_map, 'cache_size_kb'):
                st.sidebar.markdown("---")
                st.sidebar.markdown(f"**üìÅ Cache b·∫£n ƒë·ªì:** {traffic_map.cache_size_kb:.1f} KB")

            # C·∫£nh b√°o khi ƒëang ·ªü ch·∫ø ƒë·ªô t·∫£i n·∫∑ng
            if "To√†n Th√†nh Ph·ªë" in display_name:
                st.warning("‚ö†Ô∏è ƒêang xem ch·∫ø ƒë·ªô to√†n th√†nh ph·ªë. Ch·ªâ hi·ªÉn th·ªã c√°c tr·ª•c ƒë∆∞·ªùng ch√≠nh ƒë·ªÉ tr√°nh treo m√°y.")

            # Hi·ªÉn th·ªã th√¥ng tin chi ti·∫øt
            col1, col2, col3 = st.columns(3)
            with col1:
                st.info(f"üé® M√†u ƒë∆∞·ªùng: xanh d∆∞∆°ng (#3388ff)")

            with col2:
                st.info(f"üìè T·ªïng s·ªë tuy·∫øn ƒë∆∞·ªùng: {len(edges)}")

            with col3:
                st.info(f"üìè T·ªïng chi·ªÅu d√†i: {total_length_km:.1f} km")

            # Th√¥ng tin v·ªÅ s·ªë l∆∞·ª£ng ƒë√£ hi·ªÉn th·ªã
            if displayed_edges < len(edges):
                st.warning(
                    f"‚ö†Ô∏è Hi·ªÉn th·ªã {displayed_edges}/{len(edges)} tuy·∫øn ƒë∆∞·ªùng ({displayed_length_km:.1f}/{total_length_km:.1f} km) ƒë·ªÉ ƒë·∫£m b·∫£o hi·ªáu su·∫•t")

            # Th√¥ng tin ƒë·∫∑c bi·ªát cho Qu·∫≠n 1
            if display_name == "Qu·∫≠n 1" and detailed_mode:
                st.success(f"""
                **Qu·∫≠n 1 - Ch·∫ø ƒë·ªô chi ti·∫øt:**
                - Hi·ªÉn th·ªã t·∫•t c·∫£ c√°c lo·∫°i ƒë∆∞·ªùng: ƒë∆∞·ªùng l·ªõn, ƒë∆∞·ªùng ph·ª•, h·∫ªm, ng√µ
                - ƒê·ªô d√†y ƒë∆∞·ªùng ƒë∆∞·ª£c ph√¢n bi·ªát theo lo·∫°i ƒë∆∞·ªùng
                - C√°c ƒë·ªãa ƒëi·ªÉm n·ªïi ti·∫øng ƒë∆∞·ª£c ƒë√°nh d·∫•u b·∫±ng icon ƒë·ªè
                - Hi·ªÉn th·ªã th√¥ng tin chi ti·∫øt khi click v√†o t·ª´ng ƒë∆∞·ªùng (bao g·ªìm chi·ªÅu d√†i th·ª±c t·∫ø)
                - T·ªïng chi·ªÅu d√†i ƒë∆∞·ªùng: {total_length_km:.1f} km
                """)

            # N√∫t t·∫£i b·∫£n ƒë·ªì v·ªÅ m√°y
            st.sidebar.markdown("---")
            if st.sidebar.button("üíæ T·∫£i b·∫£n ƒë·ªì v·ªÅ m√°y"):
                # T·∫°o t√™n file an to√†n
                safe_name = "".join(c for c in display_name if c.isalnum() or c in (' ', '-', '_')).rstrip()
                file_name = f"map_{safe_name}.html"
                file_path = os.path.join(CACHE_DIR, file_name)

                try:
                    traffic_map.save(file_path)
                    st.sidebar.success(f"‚úÖ ƒê√£ l∆∞u: {file_name}")
                    st.sidebar.info(f"üìÅ V·ªã tr√≠: {os.path.abspath(file_path)}")
                except Exception as e:
                    st.sidebar.error(f"‚ùå L·ªói: {e}")


if __name__ == "__main__":
    main()